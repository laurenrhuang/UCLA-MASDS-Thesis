---
title: "MASDS Thesis - Bayesian model all past data - El Monte"
author: "Lauren Huang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read in Data

```{r}
# load necessary packages
library(utils)
library(dplyr)
library(purrr)
library(fs)
library(stringr)
library(lubridate)
require(stelfi)
library(PtProcess)
library(stats)
library(tidyr)
library(ggplot2)
library(foreach)
library(parallel)
library(purrr)
library(inlabru)
library(INLA)
library(sn)
library(rstan)
library(brms)
library(bayesplot)
library(patchwork)
library(reshape2)
```

```{r}
# parent directory containing relevant folders
parent_dir <- "C:/Users/cupca/Desktop/UCLA/Thesis"

# all folders within the parent directory
folder_list <- dir_ls(path = parent_dir, type = "dir")

# Specify the folders within the parent directory
folders <- c("2020", "2021", "2022", "2023")

# Construct full paths to the specified directories
full_paths <- file.path(parent_dir, folders)

# a function to read and standardize columns of each csv file
read_and_standardize <- function(file) {

  df <- read.csv(file)
  
  # convert certain columns to the same format
  columns_to_convert <- c("Cases", "Case.Rate")

  # replace occurrences of -- with 0
  value_to_replace <- "--"
  
  # convert occurrences of the specific character value in the specified columns to integer 0
  df <- df %>%
  mutate(across(all_of(columns_to_convert), 
                 ~ ifelse(. == value_to_replace, 0, .))) %>%
  mutate(across(all_of(columns_to_convert), 
                 ~ as.numeric(as.character(.))))
  
  # standardize columns: add NA/missing columns if they do not exist
  if (!("Deaths" %in% names(df))) {
    df$Deaths <- NA
  }
  if (!("Death.Rate" %in% names(df))) {
    df$Death.Rate <- NA
  }
  
  return(df)
}

# read, combine all csv files from all folders
all_covid_data <- full_paths %>%
  # list all csv files in the folder
  map(~ dir_ls(path = .x, regexp = "\\.csv$", type = "file")) %>%
  # flatten list of file paths
  unlist() %>%
  # read, standardize each csv file
  map_df(read_and_standardize, .id = "source_id")

# save combined files to a new csv file
write.csv(all_covid_data, "all_covid_data.csv", row.names = FALSE)
```


## Data Cleaning

```{r}
# define a function that relabels source_id as Year
replace_if_contains <- function(df, substring_to_find, new_value) {
  
  # replace values containing the substring in the specified column (source_id)
  df <- df %>%
    mutate(source_id = ifelse(str_detect(source_id, substring_to_find), new_value, source_id))
  
  return(df)
}

# call the function
all_covid_data <- replace_if_contains(df=all_covid_data, substring_to_find="2020", new_value="2020")
all_covid_data <- replace_if_contains(df=all_covid_data, substring_to_find="2021", new_value="2021")
all_covid_data <- replace_if_contains(df=all_covid_data, substring_to_find="2022", new_value="2022")
all_covid_data <- replace_if_contains(df=all_covid_data, substring_to_find="2023", new_value="2023")

# rename column as "Year"
names(all_covid_data)[names(all_covid_data) == 'source_id'] <- 'year'

# print modified data frame
print(all_covid_data)
```

```{r}
# Date Preprocessing

# extract month
all_covid_data$month <- substr(all_covid_data$date, nchar(all_covid_data$date) - 3, nchar(all_covid_data$date) - 2)

# extract day
all_covid_data$day <- substr(all_covid_data$date, nchar(all_covid_data$date) - 1, nchar(all_covid_data$date))

# create a column containing the full date (month, day, year)
all_covid_data$date <- as.Date(paste(all_covid_data$month, all_covid_data$day, all_covid_data$year), "%m%d%Y")

# drop individual month, day, year columns we no longer need
all_covid_data <- subset(all_covid_data, select = -c(year, month, day))
all_covid_data
```

```{r}
# create new column called incidence, counting new deaths per day in each community
all_covid_data <- all_covid_data %>%
  arrange(name, date) %>%
  group_by(name) %>%
  mutate(incidence = Deaths - lag(Deaths, default = 0)) %>%
  ungroup()

# replace negative or NA values in the incidence column with 0
all_covid_data <- all_covid_data %>%
  mutate(incidence = ifelse(is.na(incidence) | incidence < 0, 0, incidence))

# create new column called case_incidence, counting new cases per day in each community
all_covid_data <- all_covid_data %>%
  arrange(name, date) %>%
  group_by(name) %>%
  mutate(case_incidence = Cases - lag(Cases, default = 0)) %>%
  ungroup()

# replace negative or NA values in the case_incidence column with 0
all_covid_data <- all_covid_data %>%
  mutate(case_incidence = ifelse(is.na(case_incidence) | case_incidence < 0, 0, case_incidence))

tail(all_covid_data)
```

```{r}
# replace NA values with 0
all_covid_data <- all_covid_data %>%
  mutate(Deaths = ifelse(is.na(Deaths), 0, Deaths))

# convert the date column to Date type
community_data <- all_covid_data %>%
  mutate(date = as.Date(date)) %>%
  filter(date > 0) %>%
  filter(('2020-05-16' < date) & (date < '2023-01-02')) 
# excluding these dates, there is a gap between 11/21/22 - 1/2/23 and 1/3/23-11/21/23

# replace NA, 0 deaths with 0.5 or 1
community_data <- community_data %>%
  mutate(Deaths = ifelse(is.na(Deaths), 0.5, Deaths),
         Deaths = ifelse(Deaths == 0, 0.5, Deaths))

# convert dates to numeric time (days since the start of the data)
start_date <- min(community_data$date, na.rm = TRUE)
community_data <- community_data %>%
  mutate(time = as.numeric(difftime(date, start_date, units = "days")))

# look for NA values, remove rows with invalid times
community_data <- community_data %>%
  filter(!is.na(time))

# there can be no "simultaneous events" (ex. there are multiple deaths on a day), so need to transform event times
generate_event_times <- function(time, deaths) {
  if (deaths > 0) {
    # distribute event times uniformly within the same day
    return(time + runif(deaths, min = 0, max = 1))  # random times within the day
  } else {
    return(NULL)  # no deaths on this day
  }
}

# generate event times for each community
event_times_df <- community_data %>%
  group_by(name) %>%
  summarise(event_times = list(unlist(mapply(generate_event_times, time, incidence)))) 
# try using death incidence instead of cumulative deaths (Deaths)

# Santa Monica
event_times_santa_monica <- event_times_df %>%
  filter(name == "City of Santa Monica") %>%
  pull(event_times)
#print(event_times_santa_monica)

# Silverlake
event_times_silverlake <- event_times_df %>%
  filter(name == "Los Angeles - Silverlake") %>%
  pull(event_times)
#print(event_times_silverlake)

# Pomona
event_times_pomona <- event_times_df %>%
  filter(name == "City of Pomona") %>%
  pull(event_times)
#print(event_times_pomona)

# Glendale
event_times_glendale <- event_times_df %>%
  filter(name == "City of Glendale") %>%
  pull(event_times)
#print(event_times_glendale)

# El Monte
event_times_el_monte<- event_times_df %>%
  filter(name == "City of El Monte") %>%
  pull(event_times)
#print(event_times_el_monte)

# Little Armenia
event_times_little_armenia <- event_times_df %>%
  filter(name == "Los Angeles - Little Armenia") %>%
  pull(event_times)
#print(event_times_little_armenia)

# Signal Hill
event_times_signal_hill <- event_times_df %>%
  filter(name == "City of Signal Hill") %>%
  pull(event_times)
#print(event_times_signal_hill)


# sort and get unique event times
# Santa Monica
event_times_santa_monica <- sort(unlist(event_times_santa_monica))
event_times_santa_monica_unique <- unique(event_times_santa_monica)
adj_event_times_santa_monica <- event_times_santa_monica_unique + seq(0, length(event_times_santa_monica_unique) - 1) * 1e-5
# Silverlake
event_times_silverlake <- sort(unlist(event_times_silverlake))
event_times_silverlake_unique <- unique(event_times_silverlake)
adj_event_times_silverlake <- event_times_silverlake_unique + seq(0, length(event_times_silverlake_unique) - 1) * 1e-5
# Pomona
event_times_pomona <- sort(unlist(event_times_pomona))
event_times_pomona_unique <- unique(event_times_pomona)
adj_event_times_pomona <- event_times_pomona_unique + seq(0, length(event_times_pomona_unique) - 1) * 1e-5
# Glendale
event_times_glendale <- sort(unlist(event_times_glendale))
event_times_glendale_unique <- unique(event_times_glendale)
adj_event_times_glendale <- event_times_glendale_unique + seq(0, length(event_times_glendale_unique) - 1) * 1e-5
# El Monte
event_times_el_monte <- sort(unlist(event_times_el_monte))
event_times_el_monte_unique <- unique(event_times_el_monte)
adj_event_times_el_monte <- event_times_el_monte_unique + seq(0, length(event_times_el_monte_unique) - 1) * 1e-5
# Little Armenia
event_times_little_armenia <- sort(unlist(event_times_little_armenia))
event_times_little_armenia_unique <- unique(event_times_little_armenia)
adj_event_times_little_armenia <- event_times_little_armenia_unique + seq(0, length(event_times_little_armenia_unique) - 1) * 1e-5
# Signal Hill
event_times_signal_hill <- sort(unlist(event_times_signal_hill))
event_times_signal_hill_unique <- unique(event_times_signal_hill)
adj_event_times_signal_hill <- event_times_signal_hill_unique + seq(0, length(event_times_signal_hill_unique) - 1) * 1e-5
```

```{r}
# replace NA values with 0 for incidence
all_covid_data <- all_covid_data %>%
  mutate(Deaths = ifelse(is.na(Deaths), 0, Deaths))

# convert the date column to Date type
community_data <- all_covid_data %>%
  mutate(date = as.Date(date)) %>%
  filter(date > 0) %>%
  filter(('2020-05-16' < date) & (date < '2023-01-02'))  # Filtering gaps in dates

# replace NA, 0 cases with 0.5 or 1
community_data <- community_data %>%
  mutate(Deaths = ifelse(is.na(Deaths), 0.5, Deaths),
         Deaths = ifelse(Deaths == 0, 0.5, Deaths))

# convert dates to numeric time (days since the start of the data)
start_date <- min(community_data$date, na.rm = TRUE)
community_data <- community_data %>%
  mutate(time = as.numeric(difftime(date, start_date, units = "days")))

# remove rows with invalid times
community_data <- community_data %>%
  filter(!is.na(time))

# Santa Monica
santa_monica <- community_data %>%
  filter(name == "City of Santa Monica")

# Silverlake
silverlake <- community_data %>%
  filter(name == "Los Angeles - Silverlake")

# Pomona
pomona <- community_data %>%
  filter(name == "City of Pomona")

# Glendale
glendale <- community_data %>%
  filter(name == "City of Glendale")

# El Monte
el_monte <- community_data %>%
  filter(name == "City of El Monte")

# Little Armenia
little_armenia <- community_data %>%
  filter(name == "Los Angeles - Little Armenia")

# Signal Hill
signal_hill <- community_data %>%
  filter(name == "City of Signal Hill")
```

## Age data

```{r}
# age distribution data: yrs 0-9, 10-19, 20-29,...70-79, 80+
age_labels <- c("0-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-79", "80+")

# santa monica
age_data_sm <- c(5544, 6775, 9767, 18200, 11240, 12473, 11598, 8768, 5574) # census reporter

# silverlake
age_data_s <- c(3180, 2920, 5040, 5760, 4950, 3240, 2160, 1440, 900) # city data

# pomona
age_data_p <- c(15552, 17071, 22673, 23058, 20584, 18582, 15188, 8959, 3822) # census reporter

# glendale
age_data_g <- c(16839, 20343, 20629, 28874, 26031, 23322, 24892, 17068, 9034) # census reporter

# el monte
age_data_em <- c(10628, 15791, 14855, 12717, 12851, 13337, 12408, 7863, 3332) # census reporter

# little armenia
age_data_la <- c(2790, 2835, 3510, 3600, 2700, 1980, 1530, 1215, 720) # city data

# signal hill
age_data_sh <- c(981, 1240, 1360, 2127, 1782, 1759, 1400, 558, 356) # census reporter
```

### Prepare data for model

Note: Code below adapted from tutorial in the article "Approximation of Bayesian Hawkes 
process with inlabru" by Francesco Serafini, Finn Lindgren, Mark Naylor

https://github.com/Serra314/Hawkes_process_tutorials/tree/main/how_to_build_Hawkes

```{r}
# each death incidence be its own observation
el_monte <- community_data %>% filter(name == "City of El Monte")

# one row per death occurrence
dd.data <- el_monte %>%
  filter(incidence > 0) %>% 
  uncount(incidence, .id = "death_num") %>%
  mutate(
    time_date = as.POSIXct(paste0(date)),
    # small random offset to prevent same time
    time.diff = as.numeric(difftime(time_date, min(time_date) - 1, units = 'days')) +
                runif(n(), -0.001, 0.001)
  ) %>%
  arrange(time_date)

# data for inlabru
data.bru <- data.frame(ts = dd.data$time.diff) %>%
  mutate(idx.p = 1:nrow(dd.data))

T1 = 0
T2 <- max(data.bru$ts)
age_prop <- age_data_em / sum(age_data_em)
```

```{r}
# intensity function
lambda_ <- function(th, t, ti.v, segment_info, age_data) {
  age_prop <- age_data / sum(age_data)
  mu <- exp(sum(th$alpha_age * age_prop))
  if (is.null(ti.v) || all(ti.v > t)) return(mu)
  
  intervals <- findInterval(ti.v, segment_info$breaks)
  intervals[intervals == 0] <- 1  # prevent 0 indexing
  intervals[intervals > nrow(segment_info)] <- nrow(segment_info)  # cap at max

  seg_info <- segment_info[intervals, ]
  
  K_values <- th$K_vec[seg_info$K_idx]
  c_values <- th$c_vec[seg_info$c_idx]
  
  triggered_intensity <- sum(K_values * exp(-(t - ti.v)/c_values))  # Exponential
  mu + triggered_intensity
}

# log integrated intensity function
log.Lambda_h <- function(th, ti.v, T1, T2, segment_info, age_data) {
  age_prop <- age_data / sum(age_data)
  mu <- exp(sum(th$alpha_age * age_prop))
  background <- mu * (T2 - T1)
  
  if (is.null(ti.v)) return(rep(background, length(T1)))
  
  intervals <- findInterval(ti.v, segment_info$breaks)
  intervals[intervals == 0] <- 1  # prevent 0 indexing
  intervals[intervals > nrow(segment_info)] <- nrow(segment_info)  # cap at max

  seg_info <- segment_info[intervals, ]
  K_values <- th$K_vec[seg_info$K_idx]
  c_values <- th$c_vec[seg_info$c_idx]
  
  T_low <- pmax(T1, ti.v)
  triggered <- K_values * c_values * (exp(-(T_low - ti.v)/c_values) - exp(-(T2 - ti.v)/c_values))
  
  background + triggered
}

# segment breaks
K_breaks <- c(0, 60, 120, 180, 270, 450, Inf)
c_breaks <- c(0, 180, 360, Inf)

# num segments = length(K_breaks) - 1
num_K_segments <- length(K_breaks) - 1
num_c_segments <- length(c_breaks) - 1
K_idx <- 1:num_K_segments
c_idx <- findInterval(K_breaks[-length(K_breaks)], c_breaks)
# one row per segment
segment_info <- data.frame(
  breaks = K_breaks[-length(K_breaks)],
  K_idx = K_idx,
  c_idx = c_idx
)
# include the last Inf break
segment_info <- rbind(segment_info, data.frame(
  breaks = Inf,
  K_idx = num_K_segments,
  c_idx = tail(c_idx, 1)
))

time.grid <- function(data.point, coef.t, delta.t, T2., displaygrid = FALSE, N.exp.) {
  tt. <- data.point["ts"]
  idx.p <- data.point["idx.p"]
  # bins
  t_b <- breaks_exp(tt., T2., coef.t. = coef.t, delta.t. = delta.t, N.exp. = N.exp.)
  time.bins <- data.frame(
    t.start = as.numeric(t_b[-length(t_b)]),
    t.end = as.numeric(t_b[-1])
  ) %>%
    mutate(t.bin.name = paste0(round(t.start, 3), '-', round(t.end, 3)))
  if (nrow(time.bins) - 1 == 0) {
    time.bins$t.ref_layer <- paste0('last-', idx.p)
  } else {
    time.bins$t.ref_layer <- c(1:(nrow(time.bins) - 1), paste0('last-', idx.p))
  }
  cbind(time.bins, data.point, row.names = NULL)
}

breaks_exp <- function(tt_, T2_, coef.t., delta.t., N.exp.) {
  tt_breaks <- tt_ + delta.t. * ((1 + coef.t.)^(0:N.exp.))
  tt_breaks <- tt_breaks[tt_breaks < T2_]
  
  if (length(tt_breaks) == 0) {
    return(c(tt_, T2_))
  }

  if ((T2_ - max(tt_breaks)) > delta.t.) {
    tt_breaks <- c(tt_breaks, T2_)
  }
  return(tt_breaks)
}

# gamma copula transformation
gamma.t <- function(x, a, b){
  bru_forward_transformation(qgamma, x, a, b)
}
# uniform copula transformation
unif.t <- function(x, a, b){
  bru_forward_transformation(qunif, x, min = a, max = b)
}
# log-gaussian copula transformation
loggaus.t <- function(x, m, s){
  bru_forward_transformation(qlnorm, x, meanlog = m, sdlog = s)
}
# beta transformation
beta.t <- function(x, a, b){
  bru_forward_transformation(qbeta, x, shape1 = a, shape2 = b)
}

set.seed(1)
# get sample from standard gaussian distribution
st.gaussian.sample <- rnorm(10000)
gamma.values <- gamma.t(st.gaussian.sample, 1, 2)
unif.values <- unif.t(st.gaussian.sample, 0, 5)
loggaus.values <- loggaus.t(st.gaussian.sample, 0.5, 0.5)
beta.values <- beta.t(st.gaussian.sample, 2, 2)

link.f.be <- list(
  mu = \(x) gamma.t(x, 2, 5),
  K1 = \(x) gamma.t(x, 2, 3),
  K2 = \(x) gamma.t(x, 2, 3),
  K3 = \(x) gamma.t(x, 2, 3),
  K4 = \(x) gamma.t(x, 2, 3),
  K5 = \(x) gamma.t(x, 2, 3),
  K6 = \(x) gamma.t(x, 2, 3),
  c1 = \(x) gamma.t(x, 4, 2),
  c2 = \(x) gamma.t(x, 4, 2),
  c3 = \(x) gamma.t(x, 4, 2),
  alpha_age1 = \(x) unif.t(x, -2, 2),
  alpha_age2 = \(x) unif.t(x, -1, 1),
  alpha_age3 = \(x) unif.t(x, -1, 1),
  alpha_age4 = \(x) unif.t(x, -1, 1),
  alpha_age5 = \(x) unif.t(x, -1, 1),
  alpha_age6 = \(x) unif.t(x, -1, 1),
  alpha_age7 = \(x) unif.t(x, -1, 1),
  alpha_age8 = \(x) unif.t(x, -1, 1)
)

# model components
cmp.part <- counts ~ -1 +
  th.mu(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.K1(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.K2(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.K3(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.K4(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.K5(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.K6(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.c1(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.c2(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.c3(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age1(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age2(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age3(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age4(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age5(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age6(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age7(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
  th.alpha_age8(1, model = 'linear', mean.linear = 0, prec.linear = 1)

# predictor function
predictor.fun <- function(th.mu, 
                         th.K1, th.K2, th.K3, th.K4, th.K5, th.K6,
                         th.c1, th.c2, th.c3,
                         th.alpha_age1, th.alpha_age2, th.alpha_age3, th.alpha_age4,
                         th.alpha_age5, th.alpha_age6, th.alpha_age7, th.alpha_age8,
                         list.input, T1, T2,
                         link.functions = NULL, age_data) {
  
  out <- rep(0, list.input$n)

  # background component
  alpha_vec <- c(link.functions$alpha_age1(th.alpha_age1[1]),
                 link.functions$alpha_age2(th.alpha_age2[1]),
                 link.functions$alpha_age3(th.alpha_age3[1]),
                 link.functions$alpha_age4(th.alpha_age4[1]),
                 link.functions$alpha_age5(th.alpha_age5[1]),
                 link.functions$alpha_age6(th.alpha_age6[1]),
                 link.functions$alpha_age7(th.alpha_age7[1]),
                 link.functions$alpha_age8(th.alpha_age8[1]))
  
  # background intensity
  if (length(list.input$idx.bkg) > 0) {
    mu_val <- link.functions$mu(th.mu[1])
    
    if (length(mu_val) == 0 || !is.finite(mu_val)) {
      stop("link.functions$mu(th.mu[1]) returned an invalid value.")
    }

    # dot product of age effect and population
    age_contrib <- sum(alpha_vec * age_data)
    
    eta_bkg <- log(mu_val) + age_contrib + log(T2 - T1)
    out[list.input$idx.bkg] <- eta_bkg
  }

  # triggered component
  theta_ <- list(
    K_vec = c(link.functions$K1(th.K1[1]),
              link.functions$K2(th.K2[1]),
              link.functions$K3(th.K3[1]),
              link.functions$K4(th.K4[1]),
              link.functions$K5(th.K5[1]),
              link.functions$K6(th.K6[1])),
    c_vec = c(link.functions$c1(th.c1[1]),
              link.functions$c2(th.c2[1]),
              link.functions$c3(th.c3[1])),
    mu = link.functions$mu(th.mu[1]),
    alpha_age = alpha_vec
  )
  
  time.sel <- list.input$time.sel
  tth <- as.numeric(time.sel$ts)
  T1b <- as.numeric(time.sel$t.start)
  T2b <- as.numeric(time.sel$t.end)
  
  seg_info <- segment_info[findInterval(tth, segment_info$breaks), ]
  c_values <- theta_$c_vec[seg_info$c_idx]
  
  T.l <- pmax(tth, T1b)
  comp. <- theta_$K_vec[seg_info$K_idx] * c_values * 
           (exp(-(T.l - tth)/c_values) - exp(-(T2b - tth)/c_values))
  
  out[list.input$idx.trig] <- log(theta_$K_vec[list.input$df_grid$K_idx] + 1e-100) + 
                               log(comp.[list.input$Imapping] + 1e-100)

  # event-specific intensity
  theta_$mu <- link.functions$mu(th.mu[1])
  out[list.input$idx.sl] <- mean(unlist(lapply(list.input$sample.s$ts, function(x) {
    th_x <- list.input$sample.s$ts < x
    log(lambda_(theta_, x, list.input$sample.s$ts[th_x], segment_info, age_data))
  })))
  # validation checks
  if (any(!is.finite(out))) {
    stop("Non-finite values in predictor output")
  }
  out
}

# initial values
th.init <- list(
  th.mu = 0,  # log(1)
  th.K1 = 0, th.K2 = 0, th.K3 = 0, th.K4 = 0, th.K5 = 0, th.K6 = 0,  # log(1)
  th.c1 = 0, th.c2 = 0, th.c3 = 0,  # log(1)
  th.alpha_age1 = 0, th.alpha_age2 = 0, th.alpha_age3 = 0, th.alpha_age4 = 0,
  th.alpha_age5 = 0, th.alpha_age6 = 0, th.alpha_age7 = 0, th.alpha_age8 = 0
)

Hawkes.bru <- function(sample.s, T1, T2, link.functions = NULL, 
                      coef.t., delta.t., N.max., bru.opt, age_data) {
  
  df.0 <- data.frame(counts = 0, exposures = 1, part = 'background')
  
  # time bins for each observation
  cat('Creating time grid...\n')
  df.j <- foreach(idx = 1:nrow(sample.s), .combine = rbind) %do% {
    time.grid(
      data.point = sample.s[idx, ], 
      coef.t = coef.t., 
      delta.t = delta.t., 
      T2. = T2, 
      N.exp. = N.max.
    )
  }
  
  # add segment info
  idx_safe <- pmax(findInterval(df.j$ts, segment_info$breaks), 1)
  df.j$K_idx <- segment_info$K_idx[idx_safe]
  df.j$c_idx <- segment_info$c_idx[idx_safe]
  
  df.j$counts <- 0
  df.j$exposures <- 1
  df.j$part <- 'triggered'
  
  # prepare for triggered event calculation
  t.names <- unique(df.j$t.ref_layer)
  time.sel <- df.j[vapply(t.names, \(bname) match(TRUE, df.j$t.ref_layer == bname), 0L), , drop = FALSE]
  Imapping <- match(df.j$t.ref_layer, t.names)
  
  # sum of log-intensities component
  df.s <- data.frame(counts = nrow(sample.s), exposures = 0, part = 'SL')
  
  data.input <- bind_rows(df.0, df.s, df.j)
  
  list.input <- list(
    n = nrow(data.input),
    df_grid = df.j,
    Imapping = Imapping,
    time.sel = time.sel,
    sample.s = sample.s,
    idx.bkg = data.input$part == 'background',
    idx.trig = data.input$part == 'triggered',
    idx.sl = data.input$part == 'SL'
  )
  
  merged.form <- counts ~ predictor.fun(
    th.mu = th.mu, 
    th.K1 = th.K1, th.K2 = th.K2, th.K3 = th.K3,
    th.K4 = th.K4, th.K5 = th.K5, th.K6 = th.K6,
    th.c1 = th.c1, th.c2 = th.c2, th.c3 = th.c3,
    th.alpha_age1 = th.alpha_age1, th.alpha_age2 = th.alpha_age2, 
    th.alpha_age3 = th.alpha_age3, th.alpha_age4 = th.alpha_age4,
    th.alpha_age5 = th.alpha_age5, th.alpha_age6 = th.alpha_age6,
    th.alpha_age7 = th.alpha_age7, th.alpha_age8 = th.alpha_age8,
    list.input = list.input,
    T1 = T1, 
    T2 = T2, 
    link.functions = link.functions,
    age_data = age_data
  )
  
  # updated components
  cmp.part <- counts ~ -1 +
    th.mu(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.K1(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.K2(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.K3(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.K4(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.K5(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.K6(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.c1(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.c2(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.c3(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age1(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age2(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age3(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age4(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age5(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age6(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age7(1, model = 'linear', mean.linear = 0, prec.linear = 1) +
    th.alpha_age8(1, model = 'linear', mean.linear = 0, prec.linear = 1)
  
  # fit model
  cat('Fitting model...\n')
  bru(
    formula = merged.form, 
    components = cmp.part, 
    data = data.input, 
    family = 'Poisson', 
    options = append(bru.opt, list(E = data.input$exposures))
  )
}

bru.opt.list <- list(
  bru_verbose = 4,
  bru_max_iter = 200,
  inla.mode = "classic",
  control.inla = list(
    int.strategy = "eb",
    step.factor = 0.3,
    adaptive.max = 50),
  control.compute = list(config = TRUE),
  bru_initial = th.init)

# fit model
covid_fit_age_multi <- Hawkes.bru(
  sample.s = data.bru,
  T1 = 0, 
  T2 = max(data.bru$ts),
  link.functions = link.f.be,
  coef.t. = 1,
  delta.t. = 0.1,
  N.max. = 3,
  bru.opt = bru.opt.list,
  age_data = age_data_em[-9]
)

summary(covid_fit_age_multi) # converged at 8 iterations
```

```{r}
ggplot(covid_fit_age_multi$bru_iinla$track, aes(x = iteration, y = mode)) + 
  geom_line() + 
  facet_wrap(facets = vars(effect), scales = 'free')

inlabru:::make_track_plots(covid_fit_age_multi)$default
```

#### Parameters Posterior distribution

```{r}
# log-sum-exp trick to help avoid overflow
log_sum_exp <- function(x) {
  x_max <- max(x, na.rm = TRUE)
  x_max + log(sum(exp(x - x_max)))
}

# lambda.N.multi function with age covariates
lambda.N.multi <- function(th.mu, 
                          th.K1, th.K2, th.K3, th.K4, th.K5, th.K6,
                          th.c1, th.c2, th.c3,
                          th.alpha_age1, th.alpha_age2, th.alpha_age3, th.alpha_age4,
                          th.alpha_age5, th.alpha_age6, th.alpha_age7, th.alpha_age8,
                          T1, T2, Ht, link.functions, segment_info, age_data){
  
  # transform all parameters including age effects
  theta_covid <- list(
    mu = link.functions$mu(th.mu[1]),
    K_vec = c(link.functions$K1(th.K1[1]),
              link.functions$K2(th.K2[1]),
              link.functions$K3(th.K3[1]),
              link.functions$K4(th.K4[1]),
              link.functions$K5(th.K5[1]),
              link.functions$K6(th.K6[1])),
    c_vec = c(link.functions$c1(th.c1[1]),
              link.functions$c2(th.c2[1]),
              link.functions$c3(th.c3[1])),
    alpha_age = c(link.functions$alpha_age1(th.alpha_age1[1]),
                 link.functions$alpha_age2(th.alpha_age2[1]),
                 link.functions$alpha_age3(th.alpha_age3[1]),
                 link.functions$alpha_age4(th.alpha_age4[1]),
                 link.functions$alpha_age5(th.alpha_age5[1]),
                 link.functions$alpha_age6(th.alpha_age6[1]),
                 link.functions$alpha_age7(th.alpha_age7[1]),
                 link.functions$alpha_age8(th.alpha_age8[1]))
  )

  # calculate age-adjusted background rate
  age_prop <- age_data / sum(age_data)
  mu_adj <- theta_covid$mu * exp(sum(theta_covid$alpha_age * age_prop))
  
  # calculate log integrated intensity with segment-specific parameters
  logLambda_values <- log.Lambda_h(th = theta_covid, 
                                 ti.v = Ht$ts,
                                 T1 = T1, 
                                 T2 = T2,
                                 segment_info = segment_info,
                                 age_data = age_data)

  sum_exp_logLambda <- log_sum_exp(logLambda_values)  # log-sum-exp trick

  lambda_value <- mu_adj * (T2 - T1) + sum_exp_logLambda

  if (!is.finite(lambda_value)) {
    warning("lambda.N produced an infinite value. check log.Lambda_h.")
  }

  return(lambda_value)
}

# posterior prediction with age covariates
lambda.N.post <- predict(covid_fit_age_multi, 
                         data.frame(), 
                         ~ lambda.N.multi(th.mu, 
                                        th.K1, th.K2, th.K3, th.K4, th.K5, th.K6,
                                        th.c1, th.c2, th.c3,
                                        th.alpha_age1, th.alpha_age2, th.alpha_age3, th.alpha_age4,
                                        th.alpha_age5, th.alpha_age6, th.alpha_age7, th.alpha_age8,
                                        T1, T2,
                                        data.bru,
                                        link.f.be,
                                        segment_info,
                                        age_data_em[-9]))

c(lambda.N.post[1:5], true = nrow(data.bru))

# Poisson distribution prediction with age covariates
N.post <- predict(covid_fit_age_multi, data.frame(),
                  ~ data.frame(N = 200:1000,
                              pdf = dpois(200:1000,
                                         lambda.N.multi(th.mu, 
                                                       th.K1, th.K2, th.K3, th.K4, th.K5, th.K6,
                                                       th.c1, th.c2, th.c3,
                                                       th.alpha_age1, th.alpha_age2, th.alpha_age3,
                                                       th.alpha_age4, th.alpha_age5, th.alpha_age6,
                                                       th.alpha_age7, th.alpha_age8,
                                                       T1, T2,
                                                       data.bru,
                                                       link.f.be,
                                                       segment_info,
                                                       age_data_em[-9]))))

ggplot(N.post, aes(x = N, y = mean)) +
  geom_line(color = 'darkblue') +
  geom_ribbon(aes(xmax = N, xmin = N, ymin = q0.025, ymax = q0.975), alpha = 0.2,
              fill = 'blue') +
  geom_vline(xintercept = nrow(data.bru), linetype = 3) +
  geom_line(data = data.frame(x = 200:1000,
                             y = dpois(200:1000, mean(lambda.N.post$mean))),
            aes(x,y), color = 'red', linetype = 2) +
  ylab('pdf')

# sample generation
N.samp <- generate(covid_fit_age_multi, data.frame(),
                   ~ data.frame(N = 200:1000,
                               pdf = dpois(200:1000,
                                          lambda.N.multi(th.mu, 
                                                        th.K1, th.K2, th.K3, th.K4, th.K5, th.K6,
                                                        th.c1, th.c2, th.c3,
                                                        th.alpha_age1, th.alpha_age2, th.alpha_age3, 
                                                        th.alpha_age4, th.alpha_age5, th.alpha_age6,
                                                        th.alpha_age7, th.alpha_age8,
                                                        T1, T2,
                                                        data.bru,
                                                        link.f.be,
                                                        segment_info,
                                                        age_data_em[-9]))),
                   n.samples = 1, seed = 1)

ggplot(N.post, aes(x = N, y = mean)) +
  geom_line(color = 'darkblue') +
  geom_line(data = data.frame(x = 200:1000,
                             y = dpois(200:1000, mean(lambda.N.post$mean))),
            aes(x,y), color = 'red', linetype = 2) +
  geom_ribbon(aes(xmax = N, xmin = N, ymin = q0.025, ymax = q0.975), alpha = 0.2,
              fill = 'blue') +
  geom_line(data = N.samp[[1]],
            aes(x = N, y = pdf), linetype = 3) +
  ylab('pdf')
```

### Calculate expected vs observed deaths

```{r}
# get posterior mean parameters
post_means <- covid_fit_age_multi$summary.fixed$mean

# transform to original scale including age parameters
params <- list(
  mu = link.f.be$mu(post_means[1]),
  
  # excitation params
  K_vec = c(
    link.f.be$K1(post_means[2]),
    link.f.be$K2(post_means[3]),
    link.f.be$K3(post_means[4]),
    link.f.be$K4(post_means[5]),
    link.f.be$K5(post_means[6]),
    link.f.be$K6(post_means[7])
  ),
  
  # decay params
  c_vec = c(
    link.f.be$c1(post_means[8]),
    link.f.be$c2(post_means[9]),
    link.f.be$c3(post_means[10])
  ),
  
  # age parameters
  alpha_age = c(
    link.f.be$alpha_age1(post_means[11]),
    link.f.be$alpha_age2(post_means[12]),
    link.f.be$alpha_age3(post_means[13]),
    link.f.be$alpha_age4(post_means[14]),
    link.f.be$alpha_age5(post_means[15]),
    link.f.be$alpha_age6(post_means[16]),
    link.f.be$alpha_age7(post_means[17]),
    link.f.be$alpha_age8(post_means[18])
  )
)

# break points since first date
K_break_days <- c(0, 60, 120, 180, 270, 450)
c_break_days <- c(0, 180, 360)

# convert to dates
first_date <- min(el_monte$date)
K_break_dates <- first_date + K_break_days
c_break_dates <- first_date + c_break_days

segment_info <- data.frame(
  break_dates = c(K_break_dates, max(el_monte$date) + 1),
  K_idx = 1:7,
  c_idx = c(findInterval(K_break_days, c_break_days),
            tail(findInterval(K_break_days, c_break_days), 1))
)

# add final c_idx for the last segment
segment_info$c_idx[nrow(segment_info)] <- tail(findInterval(K_break_days, c_break_days), 1)


lambda_ <- function(th, t, ti.v, segment_info, age_data) {
  # calculate age-adjusted background rate
  age_prop <- age_data / sum(age_data)
  mu_adj <- th$mu * exp(sum(th$alpha_age * age_prop))
  
  if (is.null(ti.v) || all(ti.v > t)) return(mu_adj)

  # convert dates to numeric
  t_num <- as.numeric(t - first_date)
  ti.v_num <- as.numeric(ti.v - first_date)
  
  # find segments using date breaks
  seg_info <- segment_info[findInterval(ti.v, segment_info$break_dates), ]
  
  K_values <- th$K_vec[seg_info$K_idx]
  c_values <- th$c_vec[seg_info$c_idx]

  triggered_intensity <- sum(K_values * exp(-(t_num - ti.v_num) / c_values))
  mu_adj + triggered_intensity
}

time_grid <- el_monte$date
event_times <- el_monte$date

# expected intensity
expected_intensity <- sapply(time_grid, function(t) {
  lambda_(params, t, event_times[event_times < t], segment_info, age_data_em[-9])
})

# store total expected deaths for making map
total_expected_deaths_em <- sum(expected_intensity)

comparison_df <- data.frame(
  date = time_grid,
  expected = expected_intensity,
  observed = el_monte$incidence
)

bayes_6_3_el_monte_plot <- ggplot(comparison_df, aes(x = date)) +
  geom_line(aes(y = observed, color = "Observed"), linewidth = 0.8) +
  geom_line(aes(y = expected, color = "Expected"), linewidth = 0.8) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_manual(values = c("Observed" = "black", "Expected" = "red")) +
  labs(title = "Expected vs Observed COVID Deaths: El Monte",
       x = "Date", y = "Daily Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position = "right")
bayes_6_3_el_monte_plot
```

```{r}
# calculate RMSE, MAE
bayes_6_3_age_rmse <- sqrt(mean((comparison_df$observed - comparison_df$expected)^2))
bayes_6_3_age_mae <- mean(abs(comparison_df$observed - comparison_df$expected))

metrics_table <- data.frame(Community = "El Monte",
                            RMSE = bayes_6_3_age_rmse,
                            MAE = bayes_6_3_age_mae)
metrics_table
```

